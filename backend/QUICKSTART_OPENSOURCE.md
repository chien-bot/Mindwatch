# SpeakMate å¼€æºæ–¹æ¡ˆå¿«é€Ÿå¼€å§‹

## é—®é¢˜å·²è§£å†³ âœ…

ä½ é‡åˆ°çš„ "Server disconnected without sending a response" é”™è¯¯å·²ç»ä¿®å¤!

**æ ¹æœ¬åŸå› **: httpx åº“é»˜è®¤ä¼šå°è¯•ä½¿ç”¨ç³»ç»Ÿä»£ç†,å³ä½¿è®¿é—® localhost ä¹Ÿä¼šç»è¿‡ä»£ç†,å¯¼è‡´è¿æ¥å¤±è´¥ã€‚

**è§£å†³æ–¹æ¡ˆ**: åœ¨ `llm_client.py` ä¸­æ·»åŠ  `trust_env=False` å‚æ•°,ç¦ç”¨ä»£ç†è®¾ç½®ã€‚

## å½“å‰çŠ¶æ€

âœ… **Ollama**: å·²å®‰è£…å¹¶è¿è¡Œ,qwen2.5:3b æ¨¡å‹å·²ä¸‹è½½
âœ… **edge-tts**: å·²å®‰è£…,å¯ä»¥ç”Ÿæˆä¸­æ–‡è¯­éŸ³
âœ… **faster-whisper**: å·²å®‰è£…,tiny æ¨¡å‹å·²å°±ç»ª
âœ… **åç«¯æœåŠ¡**: è¿è¡Œåœ¨ http://localhost:8000
âœ… **æ‰€æœ‰æµ‹è¯•**: é€šè¿‡

## æµ‹è¯•ç»“æœ

```bash
============================================================
æµ‹è¯•ç»“æœæ±‡æ€»:
============================================================
  OLLAMA: âœ… é€šè¿‡
  TTS: âœ… é€šè¿‡
  ASR: âœ… é€šè¿‡

ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!å¼€æºæ–¹æ¡ˆå·²å°±ç»ª!
```

## å¿«é€Ÿå‘½ä»¤

### 1. å¯åŠ¨åç«¯ï¼ˆå·²åœ¨è¿è¡Œï¼‰

```bash
cd /Users/yaphowchien/speakmate/backend
uvicorn app.main:app --reload --port 8000
```

### 2. æµ‹è¯•å®Œæ•´åŠŸèƒ½

```bash
cd /Users/yaphowchien/speakmate/backend
python test_ollama.py
```

### 3. æ£€æŸ¥æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥åç«¯
curl http://localhost:8000/api/health

# æ£€æŸ¥ Ollama
curl http://localhost:11434/api/tags
```

## æ¥ä¸‹æ¥åšä»€ä¹ˆï¼Ÿ

### æ–¹æ¡ˆ 1: å¯åŠ¨å‰ç«¯

```bash
cd /Users/yaphowchien/speakmate/frontend
npm run dev
```

ç„¶åè®¿é—® http://localhost:3000

### æ–¹æ¡ˆ 2: æµ‹è¯• API ç«¯ç‚¹

```bash
# æµ‹è¯•å¯¹è¯åˆ†æï¼ˆéœ€è¦å®é™… API ç«¯ç‚¹ï¼‰
curl -X POST http://localhost:8000/api/v1/conversation/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "conversation_id": "test-123",
    "transcript": "ä½ å¥½,æˆ‘æƒ³ç»ƒä¹ é¢è¯•",
    "context": {
      "mode": "interview",
      "topic": "è‡ªæˆ‘ä»‹ç»"
    }
  }'
```

## é…ç½®æ–‡ä»¶

å½“å‰ `.env` é…ç½®:

```bash
USE_MOCK_LLM=False
USE_OPENSOURCE=True
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:3b
WHISPER_MODEL=tiny
EDGE_TTS_VOICE=zh-CN-XiaoxiaoNeural
```

## å…³é”®æ–‡ä»¶ä½ç½®

- **LLM å®¢æˆ·ç«¯**: `backend/app/core/llm_client.py`
- **é…ç½®æ–‡ä»¶**: `backend/app/core/config.py`
- **ç¯å¢ƒå˜é‡**: `backend/.env`
- **æµ‹è¯•è„šæœ¬**: `backend/test_ollama.py`
- **è¯¦ç»†æ–‡æ¡£**: `OPENSOURCE_SETUP.md`

## æ€§èƒ½å‚è€ƒï¼ˆ8GB å†…å­˜ï¼‰

| æ“ä½œ | å“åº”æ—¶é—´ | å†…å­˜å ç”¨ |
|-----|---------|---------|
| LLM å“åº” | 2-5 ç§’ | ~3-4GB |
| ASR è½¬å†™ | 3-10 ç§’ | ~200MB |
| TTS ç”Ÿæˆ | 1-3 ç§’ | ~50MB |

## å¸¸è§å‘½ä»¤

```bash
# æŸ¥çœ‹ Ollama æ¨¡å‹
ollama list

# ä¸‹è½½å…¶ä»–æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
ollama pull qwen2.5:7b

# åœæ­¢åç«¯
lsof -ti:8000 | xargs kill -9

# é‡å¯åç«¯
cd backend && uvicorn app.main:app --reload
```

## åŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | å¼€æºæ–¹æ¡ˆï¼ˆå½“å‰ï¼‰ | ä»˜è´¹æ–¹æ¡ˆ |
|-----|---------------|---------|
| LLM | Ollama qwen2.5:3b | OpenAI GPT-4 |
| ASR | faster-whisper tiny | OpenAI Whisper |
| TTS | edge-tts | OpenAI TTS |
| Vision | æ–‡å­—åˆ†æ | GPT-4 Vision |
| æˆæœ¬ | **å…è´¹** | ~$0.50/æ¬¡ |
| å“åº”é€Ÿåº¦ | 2-5 ç§’ | 1-3 ç§’ |

## åˆ‡æ¢åˆ°ä»˜è´¹æ–¹æ¡ˆ

å¦‚æœéœ€è¦æ›´å¿«çš„å“åº”é€Ÿåº¦æˆ– Vision åŠŸèƒ½:

```bash
# ä¿®æ”¹ .env
USE_OPENSOURCE=False
OPENAI_API_KEY=sk-your-api-key
```

## éœ€è¦å¸®åŠ©ï¼Ÿ

æŸ¥çœ‹è¯¦ç»†æ–‡æ¡£: `OPENSOURCE_SETUP.md`

---

**çŠ¶æ€**: ğŸŸ¢ æ‰€æœ‰æœåŠ¡è¿è¡Œæ­£å¸¸
**æœ€åæ›´æ–°**: 2025-12-16
