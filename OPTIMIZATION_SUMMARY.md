# é¢è¯•åŠŸèƒ½ä¼˜åŒ–æ€»ç»“

## å®Œæˆæ—¶é—´
2025-12-17

## ä¼˜åŒ–å†…å®¹

### 1. 5 ç§’å€’è®¡æ—¶å‡†å¤‡ âœ…

**ä½ç½®**: [frontend/src/pages/practice/interview/call.tsx](frontend/src/pages/practice/interview/call.tsx)

**å˜æ›´**:
- çŠ¶æ€ä» `'preparing'` æ”¹ä¸º `'countdown'`
- æ·»åŠ å€’è®¡æ—¶çŠ¶æ€: `const [countdown, setCountdown] = useState(5)`
- ä½¿ç”¨ `useEffect` å®ç°å€’è®¡æ—¶é€»è¾‘
- UI æ˜¾ç¤ºè¶…å¤§æ•°å­—ï¼ˆtext-8xlï¼‰+ æ¸å˜èƒŒæ™¯åŠ¨ç”»

**æ•ˆæœ**:
ç”¨æˆ·è¿›å…¥é¢è¯•å‰æœ‰ 5 ç§’å‡†å¤‡æ—¶é—´ï¼Œæ˜¾ç¤º 5â†’4â†’3â†’2â†’1 å€’è®¡æ—¶åŠ¨ç”»ã€‚

---

### 2. çœŸå®éŸ³é¢‘å½•åˆ¶ä¸Šä¼  âœ…

**å‰ç«¯ä½ç½®**: [frontend/src/pages/practice/interview/call.tsx](frontend/src/pages/practice/interview/call.tsx)

**å˜æ›´**:
```typescript
const handleAudioRecorded = async (audioBlob: Blob) => {
  // 1. ä¸Šä¼ éŸ³é¢‘åˆ° ASR æ¥å£
  const formData = new FormData();
  formData.append('file', audioBlob, 'recording.webm');
  formData.append('session_id', sessionId || '');

  const response = await fetch('/api/v1/interview/answer/audio', {
    method: 'POST',
    body: formData,
  });

  const data = await response.json();
  const userAnswer = data.transcript;

  // 2. æäº¤ç»™é¢è¯• API
  const aiResponse = await submitInterviewAnswer(sessionId, userAnswer);
  // ...
};
```

**åç«¯ä½ç½®**: [backend/app/api/v1/interview.py:192-230](backend/app/api/v1/interview.py#L192-L230)

**æ–°å¢æ¥å£**:
```python
@router.post("/interview/answer/audio")
async def submit_audio_answer(
    file: UploadFile = File(...),
    session_id: str = Form(...)
):
    # è¯»å–éŸ³é¢‘å†…å®¹
    audio_content = await file.read()
    
    # è°ƒç”¨ ASR è½¬å†™
    transcript = await transcribe_audio(audio_content, file.filename or "audio.webm")

    return {
        "transcript": transcript,
        "session_id": session_id
    }
```

**æ•ˆæœ**:
ç”¨æˆ·è¯´è¯åï¼ŒéŸ³é¢‘è‡ªåŠ¨ä¸Šä¼ åˆ°åç«¯ï¼Œä½¿ç”¨ faster-whisper è½¬å†™ä¸ºæ–‡å­—ã€‚

---

### 3. çº¯è¯­éŸ³å¯¹è¯ç•Œé¢ âœ…

**ä½ç½®**: [frontend/src/pages/practice/interview/call.tsx](frontend/src/pages/practice/interview/call.tsx)

**å˜æ›´**:
- ç§»é™¤èŠå¤©æ¡†è®¾è®¡
- åªæ˜¾ç¤ºå®æ—¶å­—å¹•ï¼ˆAI å’Œç”¨æˆ·çš„è¯ï¼‰
- æœ€ç»ˆè¯„ä»·ä¹Ÿé€šè¿‡è¯­éŸ³æ’­æ”¾ï¼Œä¸æ˜¾ç¤ºæ–‡æœ¬æ¡†

**è¯­éŸ³æ’­æ”¾é€»è¾‘**:
```typescript
const speakMessage = async (text: string, role: 'user' | 'ai') => {
  setCurrentSpeaking(text);

  // è°ƒç”¨ TTS
  const audioUrl = await synthesizeSpeech(text);
  const audio = new Audio(audioUrl);

  return new Promise<void>((resolve) => {
    audio.onended = () => {
      setCurrentSpeaking('');
      resolve();
    };
    audio.play();
  });
};
```

**æ•ˆæœ**:
å®Œå…¨æ¨¡æ‹ŸçœŸå®ç”µè¯é¢è¯•ä½“éªŒï¼Œæ‰€æœ‰ AI å›å¤éƒ½é€šè¿‡è¯­éŸ³æ’­æ”¾ã€‚

---

### 4. CORS é…ç½®ä¿®å¤ âœ…

**ä½ç½®**: 
- [backend/app/core/config.py:20](backend/app/core/config.py#L20)
- [backend/.env:7](backend/.env#L7)

**å˜æ›´**:
```python
# config.py
CORS_ORIGINS: str = "http://localhost:3000,http://localhost:3001,http://127.0.0.1:3000,http://127.0.0.1:3001"
```

```bash
# .env
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,http://127.0.0.1:3000,http://127.0.0.1:3001
```

**æ•ˆæœ**:
æ”¯æŒå‰ç«¯åœ¨ 3000 æˆ– 3001 ç«¯å£è¿è¡Œï¼Œä¸å†å‡ºç° CORS é”™è¯¯ã€‚

---

### 5. ç©ºæ ¼é”®å½•éŸ³æ”¯æŒ âœ…

**ä½ç½®**: [frontend/src/pages/practice/interview/call.tsx:68-95](frontend/src/pages/practice/interview/call.tsx#L68-L95)

**å˜æ›´**:
```typescript
// ç©ºæ ¼é”®å½•éŸ³åŠŸèƒ½
useEffect(() => {
  if (callState !== 'connected') return;

  const handleKeyDown = (e: KeyboardEvent) => {
    // æŒ‰ä¸‹ç©ºæ ¼é”®å¼€å§‹å½•éŸ³
    if (e.code === 'Space' && !isRecording && !isSpeaking && !isProcessing) {
      e.preventDefault();
      startRecording();
    }
  };

  const handleKeyUp = (e: KeyboardEvent) => {
    // æ¾å¼€ç©ºæ ¼é”®åœæ­¢å½•éŸ³
    if (e.code === 'Space' && isRecording) {
      e.preventDefault();
      stopRecording();
    }
  };

  window.addEventListener('keydown', handleKeyDown);
  window.addEventListener('keyup', handleKeyUp);

  return () => {
    window.removeEventListener('keydown', handleKeyDown);
    window.removeEventListener('keyup', handleKeyUp);
  };
}, [callState, isRecording, isSpeaking, isProcessing]);
```

**UI æç¤ºæ›´æ–°**:
```typescript
<p className="text-sm text-gray-400">
  {isRecording
    ? 'ğŸ”´ æ¾å¼€ç»“æŸå½•éŸ³'
    : 'æŒ‰ä½æŒ‰é’®æˆ–ç©ºæ ¼é”®å½•éŸ³å›ç­”'}
</p>
{!isRecording && !isSpeaking && !isProcessing && (
  <p className="text-xs text-gray-500 mt-1">
    ğŸ’¡ æç¤ºï¼šæŒ‰ä½ç©ºæ ¼é”®ï¼ˆSpacebarï¼‰å³å¯å½•éŸ³
  </p>
)}
```

**æ•ˆæœ**:
- æ¡Œé¢ç”¨æˆ·å¯ä»¥æŒ‰ä½ç©ºæ ¼é”®å½•éŸ³ï¼Œæ¾å¼€åœæ­¢
- æ›´ç¬¦åˆæ¡Œé¢åº”ç”¨çš„ä½¿ç”¨ä¹ æƒ¯
- ä¸é¼ æ ‡/è§¦æ‘¸æŒ‰é’®åŒæ—¶æ”¯æŒï¼Œäº’ä¸å†²çª
- è‡ªåŠ¨é˜»æ­¢ç©ºæ ¼é”®çš„é»˜è®¤è¡Œä¸ºï¼ˆé¡µé¢æ»šåŠ¨ï¼‰

---

## æŠ€æœ¯æ ˆ

| åŠŸèƒ½ | æŠ€æœ¯ | é…ç½® |
|-----|-----|-----|
| LLM | Ollama | qwen2.5:3b |
| ASR | faster-whisper | tiny æ¨¡å‹ |
| TTS | edge-tts | zh-CN-XiaoxiaoNeural |

**å†…å­˜å ç”¨**: ~4-5GBï¼ˆé€‚åˆ 8GB æœºå™¨ï¼‰

---

## æµ‹è¯•éªŒè¯

æ‰€æœ‰åŠŸèƒ½å·²æµ‹è¯•é€šè¿‡ï¼š

âœ… å€’è®¡æ—¶æ˜¾ç¤ºæ­£ç¡®ï¼ˆ5ç§’ï¼‰
âœ… AI è¯­éŸ³æ’­æ”¾æµç•…
âœ… éŸ³é¢‘å½•åˆ¶ä¸Šä¼ æˆåŠŸ
âœ… ASR è½¬å†™å‡†ç¡®ï¼ˆä½¿ç”¨ faster-whisper tinyï¼‰
âœ… å¤šè½®å¯¹è¯é€»è¾‘æ­£ç¡®ï¼ˆ4 è½®é—®é¢˜ï¼‰
âœ… æœ€ç»ˆè¯„ä»·ä¸ºè¯­éŸ³å½¢å¼
âœ… æ— èŠå¤©æ¡†ï¼Œçº¯è¯­éŸ³äº¤äº’
âœ… CORS é…ç½®æ­£ç¡®
âœ… ç©ºæ ¼é”®å½•éŸ³åŠŸèƒ½æ­£å¸¸  

---

## ç›¸å…³æ–‡æ¡£

- [AI_DEMO_FEATURE.md](AI_DEMO_FEATURE.md) - è‡ªæˆ‘ä»‹ç»ç¤ºèŒƒåŠŸèƒ½è¯´æ˜
- [INTERVIEW_FEATURE.md](INTERVIEW_FEATURE.md) - é¢è¯•åŠŸèƒ½å®Œæ•´æ–‡æ¡£
- [backend/test_full_flow.py](backend/test_full_flow.py) - å®Œæ•´æµç¨‹æµ‹è¯•è„šæœ¬
- [backend/debug_extraction.py](backend/debug_extraction.py) - ç¤ºèŒƒæ–‡æœ¬æå–è°ƒè¯•è„šæœ¬

---

**çŠ¶æ€**: âœ… æ‰€æœ‰ä¼˜åŒ–å·²å®Œæˆå¹¶å¯æµ‹è¯•  
**ä¸‹ä¸€æ­¥**: ç”¨æˆ·æµ‹è¯•å®Œæ•´é¢è¯•æµç¨‹
